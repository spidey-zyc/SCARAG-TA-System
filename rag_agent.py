# rag_agent.py
import re
from typing import List, Dict, Optional, Tuple
from openai import OpenAI
from config import (
    OPENAI_API_KEY,
    OPENAI_API_BASE,
    TEXT_MODEL_NAME,   # æ–‡æœ¬æ¨¡å‹
    VISION_API_KEY,    # è§†è§‰Key
    VISION_API_BASE,   # è§†è§‰Base
    VISION_MODEL_NAME, # è§†è§‰æ¨¡å‹
    TOP_K,
)
from vector_store import VectorStore

class RAGAgent:
    def __init__(self,initial_theme: str = "Default"):
        # 1. åˆå§‹åŒ–æ–‡æœ¬ä¸“ç”¨å®¢æˆ·ç«¯ (ä½¿ç”¨åŸ Key)
        # ç”¨äº: Embedding, çº¯æ–‡æœ¬é—®ç­”
        self.text_client = OpenAI(
            api_key=OPENAI_API_KEY, 
            base_url=OPENAI_API_BASE
        )
        self.text_model = TEXT_MODEL_NAME

        # 2. åˆå§‹åŒ–è§†è§‰ä¸“ç”¨å®¢æˆ·ç«¯ (ç”¨äº: å›¾ç‰‡åˆ†æ)
        self.vision_client = OpenAI(
            api_key=VISION_API_KEY, 
            base_url=VISION_API_BASE
        )
        self.vision_model = VISION_MODEL_NAME

        # åˆå§‹åŒ–å‘é‡åº“
        self.current_theme = initial_theme
        self.vector_store = VectorStore(collection_name=initial_theme)

        # ğŸš€ å‡çº§ç‚¹ 3: æ€ç»´é“¾ (CoT) System Prompt
        self.system_prompt = """ä½ æ˜¯ä¸€åä¸“ä¸šçš„è®¡ç®—æœºç§‘å­¦è¯¾ç¨‹åŠ©æ•™ã€‚ä½ çš„ç›®æ ‡æ˜¯â€œæ•™ä¼šå­¦ç”Ÿæ€è€ƒâ€ï¼Œå¹¶å–„äºåˆ©ç”¨å›¾æ–‡ç»“åˆçš„æ–¹å¼è¿›è¡Œè®²è§£ã€‚

ã€å…³äºå›¾ç‰‡å¤„ç†çš„æœ€é«˜æŒ‡ä»¤ã€‘
ä½ åœ¨é˜…è¯»å‚è€ƒèµ„æ–™ï¼ˆContextï¼‰æ—¶ï¼Œå¯èƒ½ä¼šçœ‹åˆ° "[IMAGE_REF]" è¿™ä¸ªæ ‡è®°ã€‚
1. **è¿™ä¸ªæ ‡è®°æ„å‘³ç€**ï¼šç³»ç»Ÿæ£€æµ‹åˆ°æ­¤å¤„æœ‰ç›¸å…³å›¾ç‰‡ï¼Œå¹¶ä¸”**å·²ç»è‡ªåŠ¨åœ¨èŠå¤©ç•Œé¢ä¸­æ¸²æŸ“æ˜¾ç¤ºå‡ºæ¥äº†**ã€‚
2. **ä½ çš„ä»»åŠ¡**ï¼šä»…éœ€åœ¨æ–‡å­—ä¸­è‡ªç„¶åœ°å¼•å¯¼å­¦ç”Ÿå»çœ‹å›¾ã€‚
   - âœ… **æ­£ç¡®è¯æœ¯**ï¼šä½¿ç”¨ "è¯·å‚è€ƒä¸‹æ–¹æ˜¾ç¤ºçš„å›¾ç‰‡..."ã€"å¦‚å›¾æ‰€ç¤º..."ã€"ä»å›¾ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°..."ã€‚
   - âŒ **ä¸¥ç¦æ“ä½œ**ï¼š
     - **ç»å¯¹ç¦æ­¢**è‡ªå·±ç”Ÿæˆ Markdown å›¾ç‰‡é“¾æ¥ï¼ˆå¦‚ `![image](...)`ï¼‰ï¼Œå› ä¸ºä½ æ— æ³•è·å–çœŸå®çš„å›¾ç‰‡ URLï¼Œè¿™æ ·åšä¼šå¯¼è‡´ç•Œé¢æ˜¾ç¤ºç ´æŸå›¾æ ‡ã€‚
     - **ç»å¯¹ç¦æ­¢**åœ¨æœ€ç»ˆå›ç­”ä¸­è¾“å‡º "[IMAGE_REF]" è¿™ä¸ªæ ‡è®°å­—ç¬¦ä¸²æœ¬èº«ã€‚

ã€å›ç­”æµç¨‹ã€‘
1. **æ„å›¾åˆ¤æ–­**ï¼šå¦‚æœç”¨æˆ·é—®é¢˜æ¨¡ç³Šï¼ˆå¦‚åªè¯´â€œå®ƒæ˜¯ä»€ä¹ˆâ€ï¼‰ï¼Œè¯·å…ˆåé—®æ¾„æ¸…ï¼›å¦‚æœæ¸…æ™°ï¼Œç»§ç»­ä¸‹ä¸€æ­¥ã€‚
2. **å›¾æ–‡è®²è§£ (æ ¸å¿ƒ)**ï¼š
   - ç»“åˆ Context ä¸­çš„æ–‡å­—å†…å®¹è¿›è¡Œè®²è§£ã€‚
   - å¦‚æœ Context ä¸­å‡ºç°äº† `[IMAGE_REF]`ï¼Œè¯·åŠ¡å¿…ç»“åˆè¯¥å›¾ç‰‡çš„è§†è§‰ä¿¡æ¯ï¼ˆå¦‚â€œå›¾ä¸­çš„æ–¹æ¡†è¡¨ç¤º...â€ã€â€œçº¢è‰²ç®­å¤´æŒ‡å‘...â€ï¼‰è¿›è¡Œè¾…åŠ©è¯´æ˜ï¼Œè®©è®²è§£æ›´ç›´è§‚ã€‚
3. **çŸ¥è¯†æ•´åˆ**ï¼šåŸºäº Context æå–å…³é”®äº‹å®ï¼Œå¹¶æ ‡æ³¨æ¥æºï¼Œæ ¼å¼ä¸º `[æ–‡ä»¶å, ç¬¬Xé¡µ]`ã€‚
4. **å·©å›ºæµ‹è¯•**ï¼šè®²è§£ç»“æŸåï¼Œå¿…é¡»å‡º 1 é“ç›¸å…³çš„ç»ƒä¹ é¢˜ï¼Œå¹¶é™„å¸¦ç®€è¦è§£æï¼Œå¸®åŠ©å­¦ç”Ÿå·©å›ºçŸ¥è¯†ã€‚

**è¯­æ°”è¦æ±‚**ï¼šäº²åˆ‡ã€ä¸“ä¸šã€å¾ªå¾ªå–„è¯±ã€‚
"""

    def understand_image(self, image_base64: str) -> str:
        """
        [ä¿ç•™åŸæœ‰åŠŸèƒ½] è§†è§‰åˆ†æ
        """
        print("ğŸ“¸ [Agent] æ­£åœ¨è¿›è¡Œæ·±åº¦è§†è§‰ç†è§£ä¸æè¿°...")
        vision_analysis_prompt = """
ä½ æ˜¯ä¸€ä¸ªè¾…åŠ©æ£€ç´¢ç³»ç»Ÿã€‚è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œç”Ÿæˆæœç´¢å…³é”®è¯ã€‚
1. è‹¥åŒ…å«æ–‡å­—ï¼ˆé¢˜ç›®ã€æ–‡æ¡£ï¼‰ï¼šè¯·å®Œæ•´æå–æ–‡å­—ã€‚
2. è‹¥æ˜¯å›¾è¡¨/æ¶æ„å›¾ï¼šè¯·è¯¦ç»†æè¿°è§†è§‰å†…å®¹ã€æ ¸å¿ƒæ¦‚å¿µåŠç»„ä»¶å…³ç³»ã€‚
è¦æ±‚ï¼šç›´æ¥è¾“å‡ºåˆ†æç»“æœã€‚
"""
        try:
            response = self.vision_client.chat.completions.create(
                model=self.vision_model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": vision_analysis_prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                            }
                        ]
                    }
                ],
                max_tokens=1000
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"âŒ è§†è§‰åˆ†æå¤±è´¥: {e}")
            return ""

    def rewrite_query(self, query: str, chat_history: List[Dict]) -> str:
        """
        ğŸš€ å‡çº§ç‚¹ 1: å¤šè½®å¯¹è¯æ„å›¾é‡å†™
        è§£å†³ 'å®ƒæ˜¯ä»€ä¹ˆ' è¿™ç§æŒ‡ä»£ä¸æ˜çš„é—®é¢˜
        """
        if not chat_history:
            return query

        # å–æœ€è¿‘ä¸¤è½®å¯¹è¯ä½œä¸ºå‚è€ƒ
        recent_history = chat_history[-4:]
        
        rewrite_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢é‡å†™åŠ©æ‰‹ã€‚åŸºäºä»¥ä¸‹å¯¹è¯å†å²ï¼Œå°†ç”¨æˆ·çš„æœ€æ–°é—®é¢˜é‡å†™ä¸ºä¸€ä¸ªç‹¬ç«‹ã€è¯­ä¹‰å®Œæ•´çš„æœç´¢è¯­å¥ã€‚
é‡ç‚¹ï¼šæ›¿æ¢ä»£è¯ï¼ˆå¦‚"å®ƒ"ã€"è¿™ä¸ª"ï¼‰ä¸ºå…·ä½“åè¯ã€‚

å†å²å¯¹è¯ï¼š
{recent_history}

ç”¨æˆ·æœ€æ–°é—®é¢˜ï¼š{query}

è¯·ç›´æ¥è¾“å‡ºé‡å†™åçš„é—®é¢˜ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚
"""
        try:
            # print("ğŸ¤” æ­£åœ¨ç†è§£ä¸Šä¸‹æ–‡...", end="\r")
            response = self.text_client.chat.completions.create(
                model=self.text_model,
                messages=[{"role": "user", "content": rewrite_prompt}],
                temperature=0.1
            )
            new_query = response.choices[0].message.content.strip()
            print(f"ğŸ”„ [Agent] é—®é¢˜é‡å†™: '{query}' -> '{new_query}'")
            return new_query
        except Exception as e:
            print(f"âš ï¸ é‡å†™å¤±è´¥: {e}")
            return query

    def rerank_results(self, query: str, results: List[Dict], top_k: int) -> List[Dict]:
        """
        ğŸš€ å‡çº§ç‚¹ 2: æ£€ç´¢ç»“æœé‡æ’åº (LLM Rerank)
        è®©å¤§æ¨¡å‹ä»åˆç­›ç»“æœä¸­æŒ‘å‡ºæœ€ç›¸å…³çš„
        """
        if not results:
            return []
            
        print(f"âš–ï¸ [Agent] æ­£åœ¨å¯¹ {len(results)} æ¡æ£€ç´¢ç»“æœè¿›è¡Œç²¾é€‰...")
        
        # æ„é€ ç»™ LLM çœ‹çš„å€™é€‰åˆ—è¡¨ (åªæˆªå–å‰200å­—èŠ‚çœToken)
        candidates_str = ""
        for i, res in enumerate(results):
            candidates_str += f"[ID:{i}] å†…å®¹: {res['content'][:200]}...\n\n"

        rerank_prompt = f"""
è¯·é’ˆå¯¹é—®é¢˜ï¼šâ€œ{query}â€
ä»ä»¥ä¸‹å€™é€‰ç‰‡æ®µä¸­ï¼Œé€‰å‡ºæœ€èƒ½å›ç­”è¯¥é—®é¢˜çš„ {top_k} ä¸ªç‰‡æ®µçš„IDã€‚
è¦æ±‚ï¼šåªè¾“å‡ºIDåˆ—è¡¨ï¼Œæ ¼å¼å¦‚ [0, 2, 5]ã€‚ä¸è¦è¾“å‡ºå…¶ä»–æ–‡å­—ã€‚

{candidates_str}
"""
        try:
            response = self.text_client.chat.completions.create(
                model=self.text_model,
                messages=[{"role": "user", "content": rerank_prompt}],
                temperature=0
            )
            content = response.choices[0].message.content
            # æå–æ•°å­— ID
            selected_ids = [int(d) for d in re.findall(r'\d+', content)]
            
            # æ ¹æ® ID è·å–å¯¹åº”çš„æ–‡æ¡£
            final_results = [results[i] for i in selected_ids if i < len(results)]
            
            # å…œåº•ï¼šå¦‚æœç­›é€‰ç»“æœä¸ºç©ºï¼Œå›é€€åˆ°é»˜è®¤å‰Kä¸ª
            if not final_results:
                return results[:top_k]
                
            return final_results
        except Exception as e:
            print(f"âš ï¸ é‡æ’åºå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ’åº: {e}")
            return results[:top_k]

    def retrieve_context(
        self, query: str, top_k: int = TOP_K
    ) -> Tuple[str, List[Dict]]:
        """æ£€ç´¢å¹¶æ„å»ºä¸Šä¸‹æ–‡ (åŒ…å« Rerank é€»è¾‘)"""
        
        # 1. æ‰©å¤§æ£€ç´¢èŒƒå›´ (æ£€ç´¢ 2 å€æ•°é‡ï¼Œç”¨äºç­›é€‰)
        initial_k = top_k * 2
        initial_results = self.vector_store.search(query, top_k=initial_k)
        
        # 2. æ™ºèƒ½é‡æ’åº
        final_results = self.rerank_results(query, initial_results, top_k)
        
    
        # 3. æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ (ğŸš€ å…³é”®ä¿®æ”¹åœ¨è¿™é‡Œ)
        context_parts = []
        for i, res in enumerate(final_results, 1):
            meta = res["metadata"]
            source_info = f"æ¥æº: {meta['filename']}"
            if meta.get('page_number') > 0:
                source_info += f" (ç¬¬ {meta['page_number']} é¡µ/å¹»ç¯ç‰‡)"
            
            # ğŸ‘‡ğŸ‘‡ğŸ‘‡ æ–°å¢é€»è¾‘ï¼šæ£€æŸ¥å›¾ç‰‡è·¯å¾„ ğŸ‘‡ğŸ‘‡ğŸ‘‡
            image_hint = ""
            if meta.get("image_path") and str(meta.get("image_path")).strip() != "":
                image_hint = " [IMAGE_REF]"
            
            # å°†æç¤ºè¯­æ‹¼æ¥åˆ° context ä¸­ï¼Œè®© LLM çœ‹åˆ°
            context_str = f"--- æ–‡æ¡£ç‰‡æ®µ {i} ---\n{source_info}\nå†…å®¹:\n{res['content']}{image_hint}\n"
            context_parts.append(context_str)
            
        return "\n".join(context_parts), final_results

    def generate_response(
        self,
        query: str,
        context: str,
        chat_history: Optional[List[Dict]] = None,
        image_base64: Optional[str] = None
    ) -> str:
        """ç”Ÿæˆå›ç­”ï¼šæ”¯æŒæ€ç»´é“¾ + å¤šæ¨¡æ€"""

        # === æ ¸å¿ƒä¿®æ”¹ 1: æ£€æµ‹ Context ä¸­æ˜¯å¦çœŸçš„åŒ…å«å›¾ç‰‡æ ‡è®° ===
        has_images = "[IMAGE_REF]" in context
        
        # === æ ¸å¿ƒä¿®æ”¹ 2: æ ¹æ®æ˜¯å¦æœ‰å›¾ï¼ŒåŠ¨æ€è°ƒæ•´ System Prompt ===
        if has_images:
            # Case A: æœ‰å›¾ -> ä¿æŒåŸæœ‰çš„å¼•å¯¼é€»è¾‘
            dynamic_instruction = """
ã€å…³äºå›¾ç‰‡å¼•ç”¨çš„æœ€é«˜æŒ‡ä»¤ã€‘
æ£€æµ‹åˆ°å‚è€ƒèµ„æ–™ä¸­åŒ…å«å›¾ç‰‡ï¼ˆæ ‡è®°ä¸º [IMAGE_REF]ï¼‰ã€‚
ä½ **å¿…é¡»**åœ¨å›ç­”ä¸­ç»“åˆè¿™äº›å›¾ç‰‡è¿›è¡Œè®²è§£ï¼Œä½¿ç”¨â€œå¦‚å›¾æ‰€ç¤ºâ€ã€â€œè¯·çœ‹ä¸‹å›¾â€ç­‰è¯æœ¯ï¼Œè®©å›ç­”å›¾æ–‡å¹¶èŒ‚ã€‚
"""
        else:
            # Case B: æ— å›¾ -> å¼ºåˆ¶æ³¨å…¥â€œè´Ÿå‘çº¦æŸâ€ï¼Œç¦æ­¢å¹»è§‰
            dynamic_instruction = """
ã€å…³äºå›¾ç‰‡å¼•ç”¨çš„æœ€é«˜æŒ‡ä»¤ã€‘
âš ï¸ æ£€æµ‹åˆ°å‚è€ƒèµ„æ–™ä¸­**ä¸åŒ…å«**ä»»ä½•å›¾ç‰‡ã€‚
å°½ç®¡ç”¨æˆ·å¯èƒ½è¦æ±‚â€œå›¾æ–‡å¹¶èŒ‚â€æˆ–â€œçœ‹å›¾è¯´è¯â€ï¼Œä½†ç”±äºæ•°æ®åº“ä¸­ç¼ºå¤±ç›¸å…³å›¾ç‰‡ï¼Œä½ **ç»å¯¹ç¦æ­¢**è™šæ„å›¾ç‰‡çš„å­˜åœ¨ã€‚
- âŒ ä¸¥ç¦è¯´ï¼šâ€œå¦‚å›¾æ‰€ç¤ºâ€ã€â€œä¸‹å›¾ä¸­...â€
- âœ… ä½ å¿…é¡»è¯šå®åœ°ä»…ç”¨**æ–‡å­—**è¿›è¡Œç”ŸåŠ¨ã€è¯¦ç»†çš„è§£é‡Šï¼Œä»¥æ­¤å¼¥è¡¥è§†è§‰ä¿¡æ¯çš„ç¼ºå¤±ã€‚
"""

        # å°†åŠ¨æ€æŒ‡ä»¤æ‹¼æ¥åˆ°åŸºç¡€ Prompt åé¢
        final_system_prompt = self.system_prompt + "\n" + dynamic_instruction

        # 1. åŸºç¡€æ¶ˆæ¯æ„å»º
        messages = [{"role": "system", "content": final_system_prompt}]

        if chat_history:
            messages.extend(chat_history[-4:])
        
        # 2. æ„é€ ç”¨æˆ· Prompt æ¨¡æ¿
        user_input_template = f"""
ä»¥ä¸‹æ˜¯ç›¸å…³çš„è¯¾ç¨‹ææ–™ç‰‡æ®µï¼š
{context}

---------------------
å­¦ç”Ÿé—®é¢˜ï¼š{query}

è¯·æ ¹æ®ä»¥ä¸Šææ–™ï¼ˆå¦‚æœæœ‰å›¾ç‰‡ï¼Œè¯·ç»“åˆå›¾ç‰‡å†…å®¹ï¼‰å›ç­”é—®é¢˜ï¼š
"""

        # 3. è·¯ç”±é€»è¾‘ (æœ‰å›¾ç”¨ Vision æ¨¡å‹ï¼Œæ— å›¾ç”¨ Text æ¨¡å‹)
        if image_base64:
            client = self.vision_client
            model_to_use = self.vision_model
            # æ„é€ å¤šæ¨¡æ€æ¶ˆæ¯
            content_payload = [
                {"type": "text", "text": user_input_template},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
            ]
            messages.append({"role": "user", "content": content_payload})
        else:
            client = self.text_client
            model_to_use = self.text_model
            messages.append({"role": "user", "content": user_input_template})

        try:
            response = client.chat.completions.create(
                model=model_to_use, 
                messages=messages, 
                temperature=0.3, 
                max_tokens=2000
            )
            return response.choices[0].message.content
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ æ¨¡å‹è°ƒç”¨å‡ºé”™ ({model_to_use}): {error_msg}")
            # é™çº§ä¿æŠ¤ï¼šå¦‚æœ vision æ¨¡å‹æŒ‚äº†ï¼Œå°è¯•ç”¨ text æ¨¡å‹å›å¤æ–‡å­—éƒ¨åˆ†
            if image_base64 and "text" in str(model_to_use): 
                 return f"è§†è§‰æ¨¡å‹è°ƒç”¨å¤±è´¥: {error_msg}ã€‚"
            return f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {error_msg}"

    def answer_question(
        self, query: str, chat_history: Optional[List[Dict]] = None, top_k: int = TOP_K
    ) -> str:
        """å›ç­”é—®é¢˜ä¸»å…¥å£"""
        
        # 1. æ„å›¾é‡å†™ (Query Rewrite)
        search_query = query
        if chat_history:
            search_query = self.rewrite_query(query, chat_history)

        # 2. æ£€ç´¢ (åŒ…å« Rerank)
        context, retrieved_docs = self.retrieve_context(search_query, top_k=top_k)

        # å…œåº•ç­–ç•¥
        if not context:
            context = "ï¼ˆæœªæ£€ç´¢åˆ°ç‰¹åˆ«ç›¸å…³çš„è¯¾ç¨‹ææ–™ï¼Œè¯·æ ¹æ®é€šç”¨çŸ¥è¯†è°¨æ…å›ç­”ï¼Œå¹¶å‘ŠçŸ¥å­¦ç”Ÿèµ„æ–™åº“ä¸­æ— æ­¤å†…å®¹ï¼‰"

        # 3. ç”Ÿæˆå›ç­”
        answer = self.generate_response(query, context, chat_history)

        return answer

    def chat(self) -> None:
        """æ§åˆ¶å°äº¤äº’æ¨¡å¼"""
        print("=" * 60)
        print("ğŸ¤– æ¬¢è¿ä½¿ç”¨æ™ºèƒ½è¯¾ç¨‹åŠ©æ•™ç³»ç»Ÿ (Pro Maxç‰ˆ)ï¼(è¾“å…¥ 'exit' é€€å‡º)")
        print("=" * 60)

        chat_history = []

        while True:
            try:
                query = input("\nğŸ‘¤ å­¦ç”Ÿ: ").strip()

                if query.lower() in ["exit", "quit"]:
                    print("å†è§ï¼")
                    break
                
                if not query:
                    continue
                
                print("Thinking...", end="\r") 
                
                # å‘½ä»¤è¡Œæ¨¡å¼ä¸æ”¯æŒä¼ å›¾ç‰‡ï¼Œæ‰€ä»¥ image_base64=None
                # answer_question å†…éƒ¨ä¼šè‡ªåŠ¨è°ƒç”¨ rewrite -> retrieve(rerank) -> generate
                answer = self.answer_question(query, chat_history=chat_history)

                print(f"\nğŸ“ åŠ©æ•™: \n{answer}")

                # æ›´æ–°å†å²
                chat_history.append({"role": "user", "content": query})
                chat_history.append({"role": "assistant", "content": answer})

            except KeyboardInterrupt:
                print("\nç¨‹åºå·²ç»ˆæ­¢")
                break
            except Exception as e:
                print(f"\né”™è¯¯: {str(e)}")
    def reload_knowledge_base(self, theme_name: str):
        """
        ã€æ–°å¢æ–¹æ³•ã€‘ç”¨äºåœ¨è¿è¡Œæ—¶åˆ‡æ¢çŸ¥è¯†åº“ä¸»é¢˜
        """
        if theme_name == self.current_theme:
            return # æ— éœ€åˆ‡æ¢

        print(f"ğŸ”„ [Agent] æ­£åœ¨åˆ‡æ¢çŸ¥è¯†åº“: {self.current_theme} -> {theme_name}")
        self.current_theme = theme_name
        # é‡æ–°å®ä¾‹åŒ– VectorStoreï¼ŒæŒ‡å‘æ–°çš„ Collection
        self.vector_store = VectorStore(collection_name=theme_name)