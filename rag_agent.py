# rag_agent.py
from typing import List, Dict, Optional, Tuple
from openai import OpenAI
from config import (
    OPENAI_API_KEY,
    OPENAI_API_BASE,
    MODEL_NAME,
    TOP_K,
)
from vector_store import VectorStore

class RAGAgent:
    def __init__(
        self,
        model: str = MODEL_NAME,
    ):
        self.model = model
        self.client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_BASE)
        self.vector_store = VectorStore()

        # å®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼šè®¾å®šè§’è‰²å’Œé™åˆ¶
        self.system_prompt = """ä½ æ˜¯ä¸€åä¸“ä¸šçš„è¯¾ç¨‹åŠ©æ•™ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„è¯¾ç¨‹ææ–™ï¼ˆContextï¼‰å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚

è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
1. **åŸºäºäº‹å®**ï¼šä¸¥æ ¼ä¾æ®æä¾›çš„ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚
2. **å¼•ç”¨æ¥æº**ï¼šåœ¨å›ç­”çš„å…³é”®ä¿¡æ¯åï¼Œè¯·æ³¨æ˜æ¥æºï¼Œæ ¼å¼ä¸º [æ–‡ä»¶å, ç¬¬Xé¡µ]ã€‚
3. **è¯šå®åŸåˆ™**ï¼šå¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰åŒ…å«å›ç­”é—®é¢˜æ‰€éœ€çš„ä¿¡æ¯ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥å­¦ç”Ÿâ€œå½“å‰è¯¾ç¨‹èµ„æ–™ä¸­æœªåŒ…å«æ­¤ä¿¡æ¯â€ï¼Œä¸è¦è¯•å›¾ç”¨ä½ è‡ªå·±çš„å¤–éƒ¨çŸ¥è¯†å»â€œçŒœâ€ç­”æ¡ˆï¼Œé™¤éå­¦ç”Ÿæ˜ç¡®è¦æ±‚ä½ æ‰©å±•çŸ¥è¯†ã€‚
4. **è¯­æ°”é£æ ¼**ï¼šä¿æŒäº²åˆ‡ã€é¼“åŠ±ã€ä¸“ä¸šçš„æ•™å­¦è¯­æ°”ã€‚
5. **æ ¼å¼æ¸…æ™°**ï¼šä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¦‚åˆ—è¡¨ã€ç²—ä½“ï¼‰ä½¿ç­”æ¡ˆæ˜“è¯»ã€‚
"""

    def retrieve_context(
        self, query: str, top_k: int = TOP_K
    ) -> Tuple[str, List[Dict]]:
        """æ£€ç´¢å¹¶æ„å»ºä¸Šä¸‹æ–‡"""
        results = self.vector_store.search(query, top_k=top_k)
        
        context_parts = []
        for i, res in enumerate(results, 1):
            meta = res["metadata"]
            # æ ¼å¼åŒ–å•ä¸ªæ–‡æ¡£å—
            source_info = f"æ¥æº: {meta['filename']}"
            if meta.get('page_number') > 0:
                source_info += f" (ç¬¬ {meta['page_number']} é¡µ/å¹»ç¯ç‰‡)"
            
            context_str = f"--- æ–‡æ¡£ç‰‡æ®µ {i} ---\n{source_info}\nå†…å®¹:\n{res['content']}\n"
            context_parts.append(context_str)
            
        return "\n".join(context_parts), results

    def generate_response(
        self,
        query: str,
        context: str,
        chat_history: Optional[List[Dict]] = None,
    ) -> str:
        """ç”Ÿæˆå›ç­”"""
        messages = [{"role": "system", "content": self.system_prompt}]

        # æ·»åŠ å†å²å¯¹è¯ (é™åˆ¶è½®æ•°ï¼Œé˜²æ­¢ Token æº¢å‡º)
        if chat_history:
            # åªå–æœ€è¿‘ 4 è½®å¯¹è¯
            recent_history = chat_history[-4:] 
            messages.extend(recent_history)

        # æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„ç”¨æˆ· Prompt
        user_input_template = f"""
ä»¥ä¸‹æ˜¯ç›¸å…³çš„è¯¾ç¨‹ææ–™ç‰‡æ®µï¼š
{context}

---------------------
å­¦ç”Ÿé—®é¢˜ï¼š{query}

è¯·æ ¹æ®ä»¥ä¸Šææ–™å›ç­”é—®é¢˜ï¼š
"""
        messages.append({"role": "user", "content": user_input_template})

        try:
            response = self.client.chat.completions.create(
                model=self.model, 
                messages=messages, 
                temperature=0.3, # é™ä½æ¸©åº¦ä»¥æé«˜å‡†ç¡®æ€§
                max_tokens=1500
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}"

    def answer_question(
        self, query: str, chat_history: Optional[List[Dict]] = None, top_k: int = TOP_K
    ) -> str: # ä¿®æ”¹è¿”å›ç±»å‹ä¸º str ç®€åŒ–å¤„ç†
        """å›ç­”é—®é¢˜ä¸»å…¥å£"""
        # 1. æ£€ç´¢
        context, retrieved_docs = self.retrieve_context(query, top_k=top_k)

        # 2. å¦‚æœæ£€ç´¢ç»“æœä¸ºç©ºçš„å…œåº•ç­–ç•¥
        if not context:
            context = "ï¼ˆæœªæ£€ç´¢åˆ°ç‰¹åˆ«ç›¸å…³çš„è¯¾ç¨‹ææ–™ï¼Œè¯·æ ¹æ®é€šç”¨çŸ¥è¯†è°¨æ…å›ç­”ï¼Œå¹¶å‘ŠçŸ¥å­¦ç”Ÿèµ„æ–™åº“ä¸­æ— æ­¤å†…å®¹ï¼‰"

        # 3. ç”Ÿæˆ
        answer = self.generate_response(query, context, chat_history)

        return answer

    def chat(self) -> None:
        """æ§åˆ¶å°äº¤äº’æ¨¡å¼"""
        print("=" * 60)
        print("ğŸ¤– æ¬¢è¿ä½¿ç”¨æ™ºèƒ½è¯¾ç¨‹åŠ©æ•™ç³»ç»Ÿï¼(è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º)")
        print("=" * 60)

        chat_history = []

        while True:
            try:
                query = input("\nğŸ‘¤ å­¦ç”Ÿ: ").strip()

                if query.lower() in ["exit", "quit"]:
                    print("å†è§ï¼")
                    break
                
                if not query:
                    continue
                
                print("Thinking...", end="\r") # ç®€å•çš„ç­‰å¾…æç¤º
                answer = self.answer_question(query, chat_history=chat_history)

                print(f"\nğŸ“ åŠ©æ•™: \n{answer}")

                # æ›´æ–°å†å²
                chat_history.append({"role": "user", "content": query})
                chat_history.append({"role": "assistant", "content": answer})

            except KeyboardInterrupt:
                print("\nç¨‹åºå·²ç»ˆæ­¢")
                break
            except Exception as e:
                print(f"\né”™è¯¯: {str(e)}")