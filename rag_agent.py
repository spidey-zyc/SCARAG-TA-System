# rag_agent.py
from typing import List, Dict, Optional, Tuple
from openai import OpenAI
from config import (
    OPENAI_API_KEY,
    OPENAI_API_BASE,
    TEXT_MODEL_NAME,   # å¯¼å…¥æ–‡æœ¬æ¨¡å‹å
    VISION_API_KEY,    # å¯¼å…¥è§†è§‰Key
    VISION_API_BASE,   # å¯¼å…¥è§†è§‰Base URL
    VISION_MODEL_NAME, # å¯¼å…¥è§†è§‰æ¨¡å‹å
    TOP_K,
)
from vector_store import VectorStore

class RAGAgent:
    def __init__(self):
        # 1. åˆå§‹åŒ–æ–‡æœ¬ä¸“ç”¨å®¢æˆ·ç«¯ (ä½¿ç”¨åŸ Key)
        # ç”¨äº: Embedding, çº¯æ–‡æœ¬é—®ç­”
        self.text_client = OpenAI(
            api_key=OPENAI_API_KEY, 
            base_url=OPENAI_API_BASE
        )
        self.text_model = TEXT_MODEL_NAME

        # 2. åˆå§‹åŒ–è§†è§‰ä¸“ç”¨å®¢æˆ·ç«¯ (ä½¿ç”¨æ–° Key)
        # ç”¨äº: åŒ…å«å›¾ç‰‡çš„é—®ç­”
        self.vision_client = OpenAI(
            api_key=VISION_API_KEY, 
            base_url=VISION_API_BASE
        )
        self.vision_model = VISION_MODEL_NAME

        # åˆå§‹åŒ–å‘é‡åº“
        self.vector_store = VectorStore()

        self.system_prompt = """ä½ æ˜¯ä¸€åä¸“ä¸šçš„è¯¾ç¨‹åŠ©æ•™ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„è¯¾ç¨‹ææ–™ï¼ˆContextï¼‰å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚

è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
1. **åŸºäºäº‹å®**ï¼šä¸¥æ ¼ä¾æ®æä¾›çš„ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚
2. **å¼•ç”¨æ¥æº**ï¼šåœ¨å›ç­”çš„å…³é”®ä¿¡æ¯åï¼Œè¯·æ³¨æ˜æ¥æºï¼Œæ ¼å¼ä¸º [æ–‡ä»¶å, ç¬¬Xé¡µ]ã€‚
3. **è¯šå®åŸåˆ™**ï¼šå¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰åŒ…å«å›ç­”é—®é¢˜æ‰€éœ€çš„ä¿¡æ¯ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥å­¦ç”Ÿâ€œå½“å‰è¯¾ç¨‹èµ„æ–™ä¸­æœªåŒ…å«æ­¤ä¿¡æ¯â€ï¼Œä¸è¦è¯•å›¾ç”¨ä½ è‡ªå·±çš„å¤–éƒ¨çŸ¥è¯†å»â€œçŒœâ€ç­”æ¡ˆï¼Œé™¤éå­¦ç”Ÿæ˜ç¡®è¦æ±‚ä½ æ‰©å±•çŸ¥è¯†ã€‚
4. **è¯­æ°”é£æ ¼**ï¼šä¿æŒäº²åˆ‡ã€é¼“åŠ±ã€ä¸“ä¸šçš„æ•™å­¦è¯­æ°”ã€‚
5. **æ ¼å¼æ¸…æ™°**ï¼šä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¦‚åˆ—è¡¨ã€ç²—ä½“ï¼‰ä½¿ç­”æ¡ˆæ˜“è¯»ã€‚
"""

    # rag_agent.py ä¸­ä¿®æ”¹æˆ–æ·»åŠ è¿™ä¸ªæ–¹æ³•

    def understand_image(self, image_base64: str) -> str:
        """
        å‡çº§ç‰ˆè§†è§‰åˆ†æï¼š
        - å¦‚æœæ˜¯é¢˜ç›®/æ–‡æ¡£ï¼šæå–æ–‡å­—ã€‚
        - å¦‚æœæ˜¯å›¾è¡¨/å®ç‰©ï¼šç”Ÿæˆè¯¦ç»†çš„è¯­ä¹‰æè¿°ã€‚
        """
        print("ğŸ“¸ [Agent] æ­£åœ¨è¿›è¡Œæ·±åº¦è§†è§‰ç†è§£ä¸æè¿°...")
        
        # æ ¸å¿ƒæç¤ºè¯ï¼šæŒ‡å¯¼æ¨¡å‹æ ¹æ®å›¾ç‰‡ç±»å‹é‡‡å–ä¸åŒç­–ç•¥
        vision_analysis_prompt = """
ä½ æ˜¯ä¸€ä¸ªè¾…åŠ©æ£€ç´¢ç³»ç»Ÿã€‚è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œç›®çš„æ˜¯ä¸ºäº†ç”Ÿæˆä¸€æ®µ**æœç´¢å…³é”®è¯**ï¼Œä»¥ä¾¿åœ¨è¯¾ç¨‹èµ„æ–™åº“ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹é€»è¾‘å¤„ç†ï¼š
1. **å¦‚æœæ˜¯åŒ…å«å¤§é‡æ–‡å­—çš„å›¾ç‰‡ï¼ˆå¦‚é¢˜ç›®ã€å¹»ç¯ç‰‡ã€æ–‡æ¡£æˆªå›¾ï¼‰**ï¼š
   - è¯·ç›´æ¥ã€å®Œæ•´åœ°æå–å‡ºå›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—ã€‚ä¸è¦é—æ¼é¢˜ç›®ç»†èŠ‚ã€‚

2. **å¦‚æœæ˜¯å›¾è¡¨ã€æ¶æ„å›¾ã€æµç¨‹å›¾æˆ–æ— æ–‡å­—å›¾ç‰‡**ï¼š
   - è¯·è¯¦ç»†æè¿°å›¾ç‰‡çš„**è§†è§‰å†…å®¹**ã€**æ ¸å¿ƒæ¦‚å¿µ**ã€**ç»„ä»¶åç§°**ä»¥åŠå®ƒä»¬ä¹‹é—´çš„**é€»è¾‘å…³ç³»**ã€‚
   - ä¾‹å¦‚ï¼šâ€œè¿™æ˜¯ä¸€ä¸ªäºŒå‰æ ‘çš„ç»“æ„å›¾ï¼Œæ ¹èŠ‚ç‚¹æ˜¯Aï¼Œå·¦å­èŠ‚ç‚¹æ˜¯B...â€æˆ–â€œè¿™æ˜¯ä¸€å¼ å±•ç¤ºTCPä¸‰æ¬¡æ¡æ‰‹æµç¨‹çš„æ—¶åºå›¾â€ã€‚

**è¦æ±‚**ï¼šç›´æ¥è¾“å‡ºåˆ†æç»“æœï¼ˆæ–‡å­—æˆ–æè¿°ï¼‰ï¼Œä¸è¦åŒ…å«â€œè¿™æ˜¯ä¸€å¼ å›¾ç‰‡â€ä¹‹ç±»çš„åºŸè¯ã€‚
"""

        try:
            response = self.vision_client.chat.completions.create(
                model=self.vision_model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": vision_analysis_prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                            }
                        ]
                    }
                ],
                max_tokens=1000 # ç¨å¾®è°ƒå¤§ä¸€ç‚¹ï¼Œä»¥å®¹çº³è¯¦ç»†æè¿°
            )
            analysis_result = response.choices[0].message.content
            print(f"ğŸ‘ï¸ [Agent] è§†è§‰åˆ†æç»“æœ: {analysis_result[:50]}...")
            return analysis_result
        except Exception as e:
            print(f"âŒ è§†è§‰åˆ†æå¤±è´¥: {e}")
            return ""

    def retrieve_context(
        self, query: str, top_k: int = TOP_K
    ) -> Tuple[str, List[Dict]]:
        """æ£€ç´¢å¹¶æ„å»ºä¸Šä¸‹æ–‡"""
        results = self.vector_store.search(query, top_k=top_k)
        
        context_parts = []
        for i, res in enumerate(results, 1):
            meta = res["metadata"]
            source_info = f"æ¥æº: {meta['filename']}"
            if meta.get('page_number') > 0:
                source_info += f" (ç¬¬ {meta['page_number']} é¡µ/å¹»ç¯ç‰‡)"
            
            context_str = f"--- æ–‡æ¡£ç‰‡æ®µ {i} ---\n{source_info}\nå†…å®¹:\n{res['content']}\n"
            context_parts.append(context_str)
            
        return "\n".join(context_parts), results

    def generate_response(
        self,
        query: str,
        context: str,
        chat_history: Optional[List[Dict]] = None,
        image_base64: Optional[str] = None  # æ”¯æŒæ¥æ”¶å›¾ç‰‡
    ) -> str:
        """ç”Ÿæˆå›ç­”ï¼šè‡ªåŠ¨è·¯ç”±åˆ°ä¸åŒçš„æ¨¡å‹"""
        
        # 1. åŸºç¡€æ¶ˆæ¯æ„å»º
        messages = [{"role": "system", "content": self.system_prompt}]

        if chat_history:
            messages.extend(chat_history[-4:])

        # 2. æ„é€ ç”¨æˆ· Prompt æ¨¡æ¿
        user_input_template = f"""
ä»¥ä¸‹æ˜¯ç›¸å…³çš„è¯¾ç¨‹ææ–™ç‰‡æ®µï¼š
{context}

---------------------
å­¦ç”Ÿé—®é¢˜ï¼š{query}

è¯·æ ¹æ®ä»¥ä¸Šææ–™ï¼ˆå¦‚æœæœ‰å›¾ç‰‡ï¼Œè¯·ç»“åˆå›¾ç‰‡å†…å®¹ï¼‰å›ç­”é—®é¢˜ï¼š
"""

        # 3. ğŸ”€ æ ¸å¿ƒè·¯ç”±é€»è¾‘
        if image_base64:
            # === åœºæ™¯ A: æœ‰å›¾ç‰‡ï¼Œè°ƒç”¨ Vision Model ===
            # print(f"ğŸ“¸ [Agent] æ£€æµ‹åˆ°å›¾ç‰‡è¾“å…¥ï¼Œåˆ‡æ¢è‡³è§†è§‰æ¨¡å‹: {self.vision_model}")
            client = self.vision_client
            model_to_use = self.vision_model
            
            # æ„é€ å¤šæ¨¡æ€æ¶ˆæ¯ (Listæ ¼å¼)
            content_payload = [
                {"type": "text", "text": user_input_template},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64}"
                    }
                }
            ]
            messages.append({"role": "user", "content": content_payload})
            
        else:
            # === åœºæ™¯ B: çº¯æ–‡æœ¬ï¼Œè°ƒç”¨ Text Model ===
            # print(f"ğŸ“ [Agent] çº¯æ–‡æœ¬è¾“å…¥ï¼Œä½¿ç”¨æ–‡æœ¬æ¨¡å‹: {self.text_model}")
            client = self.text_client
            model_to_use = self.text_model
            
            # æ„é€ æ™®é€šæ–‡æœ¬æ¶ˆæ¯ (Stringæ ¼å¼)
            messages.append({"role": "user", "content": user_input_template})

        try:
            response = client.chat.completions.create(
                model=model_to_use, 
                messages=messages, 
                temperature=0.3, 
                max_tokens=2000
            )
            return response.choices[0].message.content
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ æ¨¡å‹è°ƒç”¨å‡ºé”™ ({model_to_use}): {error_msg}")
            
            # è‡ªåŠ¨é™çº§ä¿æŠ¤ï¼šå¦‚æœ Vision æ¨¡å‹æŒ‚äº†ä¸”æ˜¯çº¯æ–‡æœ¬è¯·æ±‚ï¼Œå°è¯•ç”¨ Text æ¨¡å‹
            if image_base64 and "text" in str(model_to_use): 
                 return f"è§†è§‰æ¨¡å‹è°ƒç”¨å¤±è´¥: {error_msg}ã€‚"
            
            return f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {error_msg}"

    def answer_question(
        self, query: str, chat_history: Optional[List[Dict]] = None, top_k: int = TOP_K
    ) -> str:
        """å›ç­”é—®é¢˜ä¸»å…¥å£ (ä¸»è¦ä¾›æ§åˆ¶å°æˆ–ä¸å¸¦å›¾çš„UIä½¿ç”¨)"""
        # 1. æ£€ç´¢
        context, retrieved_docs = self.retrieve_context(query, top_k=top_k)

        # 2. å¦‚æœæ£€ç´¢ç»“æœä¸ºç©ºçš„å…œåº•ç­–ç•¥
        if not context:
            context = "ï¼ˆæœªæ£€ç´¢åˆ°ç‰¹åˆ«ç›¸å…³çš„è¯¾ç¨‹ææ–™ï¼Œè¯·æ ¹æ®é€šç”¨çŸ¥è¯†è°¨æ…å›ç­”ï¼Œå¹¶å‘ŠçŸ¥å­¦ç”Ÿèµ„æ–™åº“ä¸­æ— æ­¤å†…å®¹ï¼‰"

        # 3. ç”Ÿæˆ (ä¸ä¼ å…¥å›¾ç‰‡å‚æ•°ï¼Œè‡ªåŠ¨ä½¿ç”¨æ–‡æœ¬æ¨¡å‹)
        answer = self.generate_response(query, context, chat_history)

        return answer

    def chat(self) -> None:
        """æ§åˆ¶å°äº¤äº’æ¨¡å¼ (çº¯æ–‡æœ¬)"""
        print("=" * 60)
        print("ğŸ¤– æ¬¢è¿ä½¿ç”¨æ™ºèƒ½è¯¾ç¨‹åŠ©æ•™ç³»ç»Ÿï¼(è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º)")
        print("=" * 60)

        chat_history = []

        while True:
            try:
                query = input("\nğŸ‘¤ å­¦ç”Ÿ: ").strip()

                if query.lower() in ["exit", "quit"]:
                    print("å†è§ï¼")
                    break
                
                if not query:
                    continue
                
                print("Thinking...", end="\r") # ç®€å•çš„ç­‰å¾…æç¤º
                
                # è°ƒç”¨ answer_questionï¼Œå®ƒä¼šè°ƒç”¨ generate_response(image_base64=None)
                answer = self.answer_question(query, chat_history=chat_history)

                print(f"\nğŸ“ åŠ©æ•™: \n{answer}")

                # æ›´æ–°å†å²
                chat_history.append({"role": "user", "content": query})
                chat_history.append({"role": "assistant", "content": answer})

            except KeyboardInterrupt:
                print("\nç¨‹åºå·²ç»ˆæ­¢")
                break
            except Exception as e:
                print(f"\né”™è¯¯: {str(e)}")